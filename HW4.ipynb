{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set(string.ascii_lowercase + \" \")\n",
    "langs = {\"English\":\"e\", \"Japanese\":\"j\", \"Spanish\":\"s\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns disctionary of chars and their counts \n",
    "def read_file(file_name):    \n",
    "    data_file = open(os.getcwd()+\"/languageID/\"+file_name, \"r\")\n",
    "    text = data_file.read()\n",
    "    data_file.close()\n",
    "    \n",
    "    counts = {}\n",
    "    for char in s:\n",
    "        counts[char] = text.count(char)\n",
    "    \n",
    "    return dict(sorted(counts.items(), key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return dictionary of dictionaries\n",
    "# outer key: file_name\n",
    "# inner key: char\n",
    "# value: count\n",
    "def get_training_data():\n",
    "    counts_dict_dict = {}\n",
    "    for file_name in sorted(os.listdir(os.getcwd()+\"/languageID/\")):\n",
    "        if re.search(\"^(e|j|s)[0-9](?!\\d)\", file_name) is not None:\n",
    "            counts_dict_dict[file_name] = read_file(file_name)\n",
    "            \n",
    "    return counts_dict_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the prior probability of a language\n",
    "# default additive smoothing parameter 1/2\n",
    "def get_prior_prob(training_data, lang, a=0.5):\n",
    "    count = 0\n",
    "    for file_name in training_data:\n",
    "        if re.search(\"^\"+lang, file_name) is not None:\n",
    "            count += 1\n",
    "            \n",
    "    return (count + a)/(len(training_data) + a*len(langs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME?? smoothing is messing up p(x)?\n",
    "\n",
    "# returns dictionary of chars and their corresponding probabilities in training data given a language\n",
    "# normalize sets the largest prob to 1 if set to true, default false\n",
    "def get_class_cond_probs(training_data, lang=\"all\", a=0.5, normalize=False):\n",
    "    \n",
    "    # initialize return variable\n",
    "    class_cond_probs = {}\n",
    "    for char in s:\n",
    "        class_cond_probs[char] = 0\n",
    "    \n",
    "    # getting the counts conditioned on language\n",
    "    if not lang == \"all\": \n",
    "        for file_name in training_data:\n",
    "            if re.search(\"^\"+lang, file_name) is not None:\n",
    "                for char in s:\n",
    "                    class_cond_probs[char] += training_data[file_name][char]\n",
    "    # getting the counts not conditioned on language\n",
    "    else:\n",
    "        for file_name in training_data:\n",
    "            for char in s:\n",
    "                class_cond_probs[char] += training_data[file_name][char]\n",
    "    \n",
    "    # getting the probs with smoothing\n",
    "    tot_chars = 0\n",
    "    for char in class_cond_probs:\n",
    "        tot_chars += class_cond_probs[char]\n",
    "    \n",
    "    for char in class_cond_probs:\n",
    "        class_cond_probs[char] = (class_cond_probs[char] + a)/(tot_chars + a*len(s))\n",
    "    \n",
    "    # sets the largest prob to 1 if set to true, default false\n",
    "    if normalize:\n",
    "        max_prob = max(class_cond_probs.values())\n",
    "        for char in class_cond_probs:\n",
    "            class_cond_probs[char] *= (1/max_prob)\n",
    "    \n",
    "    return dict(sorted(class_cond_probs.items(), key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs_x(test_data, a=0.5):\n",
    "    probs = {}\n",
    "    for char in s:\n",
    "        probs[char] = test_data[char]\n",
    "        \n",
    "    tot_chars = 0\n",
    "    for char in probs:\n",
    "        tot_chars += probs[char]\n",
    "        \n",
    "    for char in probs:\n",
    "#         probs[char] = (probs[char] + a)/(tot_chars + a*len(s))\n",
    "        probs[char] /= tot_chars \n",
    "        \n",
    "    return dict(sorted(probs.items(), key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the log probability of count-vextor x given conditional probability vector theta\n",
    "def p_of_x_given_y(x, theta):\n",
    "    prob = 0\n",
    "    for char in s:\n",
    "        prob += x[char] * np.log(theta[char])\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: 0.3333333333333333\n",
      "Japanese: 0.3333333333333333\n",
      "Spanish: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_data()\n",
    "for lang in langs:\n",
    "    print(lang + \": \" + str(get_prior_prob(training_data, langs[lang])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Class Conditional Probabilities:\n",
      "(' ', 0.1792499586981662)\n",
      "('e', 0.1053692383941847)\n",
      "('t', 0.08012555757475633)\n",
      "('s', 0.06618205848339666)\n",
      "('o', 0.06446390219725756)\n",
      "('a', 0.0601685114819098)\n",
      "('n', 0.057921691723112505)\n",
      "('i', 0.055410540227986124)\n",
      "('r', 0.053824549810011564)\n",
      "('h', 0.047216256401784236)\n",
      "('l', 0.028977366595076822)\n",
      "('u', 0.026664463902197257)\n",
      "('d', 0.021972575582355856)\n",
      "('c', 0.021509995043779945)\n",
      "('m', 0.020518751032545846)\n",
      "('f', 0.018932760614571286)\n",
      "('g', 0.017478936064761277)\n",
      "('p', 0.01675202378985627)\n",
      "('w', 0.015496448042293078)\n",
      "('y', 0.013844374690236246)\n",
      "('b', 0.011134974392863043)\n",
      "('v', 0.009284652238559392)\n",
      "('k', 0.0037336857756484387)\n",
      "('j', 0.001420783082768875)\n",
      "('x', 0.001156451346439782)\n",
      "('z', 0.0006277878737815959)\n",
      "('q', 0.0005617049396993227)\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_data()\n",
    "class_cond_probs = get_class_cond_probs(training_data, lang=\"e\")\n",
    "\n",
    "print(\"English Class Conditional Probabilities:\")\n",
    "for item in class_cond_probs.items():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japanese Class Conditional Probabilities:\n",
      "('a', 0.1317656102589189)\n",
      "(' ', 0.12344945665466997)\n",
      "('i', 0.09703343932352633)\n",
      "('o', 0.09116321324993885)\n",
      "('u', 0.07061742199238269)\n",
      "('e', 0.06020475907613823)\n",
      "('k', 0.05740941332681086)\n",
      "('t', 0.056990111464411755)\n",
      "('n', 0.05671057688947902)\n",
      "('r', 0.04280373178657535)\n",
      "('s', 0.0421747789929767)\n",
      "('m', 0.03979873510604843)\n",
      "('h', 0.03176211607673224)\n",
      "('w', 0.01974212935462455)\n",
      "('d', 0.01722631818022992)\n",
      "('y', 0.01415143785596981)\n",
      "('g', 0.014011670568503443)\n",
      "('b', 0.010866906600510151)\n",
      "('z', 0.00772214263251686)\n",
      "('c', 0.005485866033054963)\n",
      "('f', 0.003878542227191726)\n",
      "('j', 0.0023411020650616725)\n",
      "('l', 0.001432614696530277)\n",
      "('p', 0.0008735455466648031)\n",
      "('v', 0.0002445927530661449)\n",
      "('q', 0.00010482546559977637)\n",
      "('x', 3.4941821866592126e-05)\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_data()\n",
    "class_cond_probs = get_class_cond_probs(training_data, lang=\"j\")\n",
    "\n",
    "print(\"Japanese Class Conditional Probabilities:\")\n",
    "for item in class_cond_probs.items():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish Class Conditional Probabilities:\n",
      "(' ', 0.16826493170115014)\n",
      "('e', 0.1138108599796491)\n",
      "('a', 0.10456045141993771)\n",
      "('o', 0.07249236841293824)\n",
      "('s', 0.06577040485954797)\n",
      "('r', 0.05929511886774999)\n",
      "('n', 0.054176559464709693)\n",
      "('l', 0.052943171656748174)\n",
      "('i', 0.049859702136844375)\n",
      "('d', 0.039745922111559924)\n",
      "('c', 0.03752582405722919)\n",
      "('t', 0.03561407295488884)\n",
      "('u', 0.03370232185254849)\n",
      "('m', 0.02580863988159477)\n",
      "('p', 0.02426690512164287)\n",
      "('f', 0.00860287996053159)\n",
      "('b', 0.008232863618143134)\n",
      "('y', 0.007862847275754679)\n",
      "('q', 0.007677839104560451)\n",
      "('g', 0.0071844839813758445)\n",
      "('j', 0.006629459467793161)\n",
      "('v', 0.00588942678301625)\n",
      "('h', 0.0045327001942585795)\n",
      "('z', 0.0026826184823163022)\n",
      "('x', 0.0024976103111220747)\n",
      "('k', 0.0002775122567913416)\n",
      "('w', 9.250408559711388e-05)\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_data()\n",
    "class_cond_probs = get_class_cond_probs(training_data, lang=\"s\")\n",
    "\n",
    "print(\"Spanish Class Conditional Probabilities:\")\n",
    "for item in class_cond_probs.items():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' ', 498)\n",
      "('e', 311)\n",
      "('t', 225)\n",
      "('s', 186)\n",
      "('o', 182)\n",
      "('a', 164)\n",
      "('r', 141)\n",
      "('h', 140)\n",
      "('i', 140)\n",
      "('n', 139)\n",
      "('l', 85)\n",
      "('u', 65)\n",
      "('m', 64)\n",
      "('d', 57)\n",
      "('f', 55)\n",
      "('c', 53)\n",
      "('p', 53)\n",
      "('g', 51)\n",
      "('w', 47)\n",
      "('y', 38)\n",
      "('b', 32)\n",
      "('v', 31)\n",
      "('k', 6)\n",
      "('x', 4)\n",
      "('j', 3)\n",
      "('q', 3)\n",
      "('z', 2)\n"
     ]
    }
   ],
   "source": [
    "x = read_file(\"e10.txt\")\n",
    "for item in x.items():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood - English:  -7841.865447060634\n",
      "Log Likelihood - Japanese: -8771.433079075034\n",
      "Log Likelihood - Spanish:  -8467.282044010559\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_data()\n",
    "theta_e = get_class_cond_probs(training_data, lang=\"e\")\n",
    "theta_j = get_class_cond_probs(training_data, lang=\"j\")\n",
    "theta_s = get_class_cond_probs(training_data, lang=\"s\")\n",
    "x = read_file(\"e10.txt\")\n",
    "\n",
    "print(\"Log Likelihood - English:  \" + str(p_of_x_given_y(x, theta_e)))\n",
    "print(\"Log Likelihood - Japanese: \" + str(p_of_x_given_y(x, theta_j)))\n",
    "print(\"Log Likelihood - Spanish:  \" + str(p_of_x_given_y(x, theta_s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: FIXME(P(x) very far from P(x|y))\n",
    "def get_predicted_prob(training_data, test_data, lang):\n",
    "    theta_lang = get_class_cond_probs(training_data, lang=lang)\n",
    "    theta_all = get_class_cond_probs(training_data, lang=\"all\")\n",
    "#     theta_all = get_probs_x(test_data)     used to be called theta_x\n",
    "    x = get_probs_x(test_data)\n",
    "    \n",
    "#     print(get_prior_prob(training_data, lang))\n",
    "#     print(p_of_x_given_y(test_data, theta_lang))\n",
    "#     print(p_of_x_given_y(test_data, theta_x))\n",
    "    \n",
    "#     return get_prior_prob(training_data, lang) \n",
    "#             * math.e**(p_of_x_given_y(get_probs_x(test_data), theta_lang) \n",
    "#                      - p_of_x_given_y(get_probs_x(test_data), theta_all))\n",
    "    \n",
    "\n",
    "\n",
    "    return math.e**(p_of_x_given_y(x, theta_lang)\n",
    "                    + np.log(get_prior_prob(training_data, lang))\n",
    "                    - p_of_x_given_y(x, theta_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: 0.3530348267904746\n",
      "Japanese: 0.2525444782475066\n",
      "Spanish: 0.2817982420844059\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_data()\n",
    "test_data = read_file(\"e10.txt\")\n",
    "\n",
    "for lang in langs:\n",
    "    print(lang + \": \" + str(get_predicted_prob(training_data, test_data, langs[lang])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(training_data, test_data):\n",
    "    \n",
    "    probs = {}\n",
    "    for lang in langs:\n",
    "        theta = get_class_cond_probs(training_data, langs[lang])\n",
    "#         probs[lang] = p_of_x_given_y(test_data, theta)\n",
    "        probs[lang] = get_predicted_prob(training_data, test_data, langs[lang])\n",
    "    \n",
    "#     print(\"\\n\" + str(sum(probs.values())))\n",
    "    return max(probs, key=probs.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_data()\n",
    "test_data = read_file(\"e10.txt\")\n",
    "\n",
    "print(make_prediction(training_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "English: English\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Japanese: Japanese\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n",
      "Spanish: Spanish\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_data()\n",
    "for file_name in sorted(os.listdir(os.getcwd()+\"/languageID/\")):\n",
    "    test_data = read_file(file_name)\n",
    "    \n",
    "    print(list(langs.keys()) [list(langs.values()).index(file_name[0])] + \": \" +\n",
    "         make_prediction(training_data, get_probs_x(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
